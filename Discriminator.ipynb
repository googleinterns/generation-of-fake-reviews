{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Discriminator.ipynb","provenance":[{"file_id":"1v_xBs1py45520sEdc2DX7B4ghBJpT1Kj","timestamp":1595180684784}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOr5C6olU0ujG7tFQ9OC1kk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"R3FX31017xFv","colab_type":"text"},"source":["# Classifier to classify fake reviews and real reviews. <br>\n","**Files Used**<br>\n","Fake Reviews: create a list of reviews generated by the generators <br>\n","Real Reviews: https://www.kaggle.com/yelp-dataset/yelp-dataset?select=yelp_academic_dataset_review.json<br>\n"]},{"cell_type":"code","metadata":{"id":"nmGb_ej77NaN","colab_type":"code","colab":{}},"source":["#mounting the drive\n","import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth, drive\n","from oauth2client.client import GoogleCredentials\n","\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Gx1m9N87gTz","colab_type":"code","colab":{}},"source":["#importing the libraries\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import random\n","from random import choice\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_recall_curve,precision_score\n","from keras.preprocessing.sequence import pad_sequences\n","from matplotlib import pyplot\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZzFLNN-V8tNv","colab_type":"code","colab":{}},"source":["import nltk\n","nltk.download(\"punkt\")\n","nltk.download(\"stopwords\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9v5VP-4I8DGp","colab_type":"code","colab":{}},"source":["from IPython.display import HTML, display\n","\n","def set_css():\n","  \"\"\" A function for wrapping text displayed in the output \"\"\"\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","  \n","get_ipython().events.register('pre_run_cell', set_css)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1TrbKZGl-zmA","colab_type":"code","colab":{}},"source":["#defining the constants\n","VOCAB_SIZE = 100000\n","INPUT_LEN = 150"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1jxx5tLd7-UJ","colab_type":"text"},"source":["# Loading the data"]},{"cell_type":"code","metadata":{"id":"Q6Hm884C8g75","colab_type":"code","colab":{}},"source":["with open(\"fake_reviews.pkl\", \"rb\") as f:\n","  fake_reviews_list = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W8YcYK_UYW5x","colab_type":"code","colab":{}},"source":["with open(\"real_reviews.pkl\", \"rb\") as f:\n","  real_reviews_list = pickle.load(f)\n","real_reviews_list = real_reviews_list[:len(fake_reviews_list)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0OLUhEnCAJ5l","colab_type":"code","colab":{}},"source":["#cleaning the fake reviews text when using VAE_50K.txt file. Has the tokens <GO>,\"\\n\"\n","for counter in range(len(real_reviews_list)):\n","  real_reviews_list[counter] = real_reviews_list[counter].replace(\"\\n\",\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VAvqcEU-8rTj","colab_type":"code","colab":{}},"source":["print(\"Number of real reviews: \", len(real_reviews_list))\n","print(\"Number of fake reviews: \",len(fake_reviews_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OnVF_aee9BJ9","colab_type":"code","colab":{}},"source":["#creating the complete reviews list\n","\n","reviews_list = fake_reviews_list.copy()\n","reviews_list.extend(real_reviews_list)\n","\n","print(\"Total number of reviews: \", len(reviews_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dwdlvcsv9MCJ","colab_type":"code","colab":{}},"source":["#preparing the labels\n","labels = [0]*len(fake_reviews_list)\n","labels.extend([1]*len(real_reviews_list))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GajprVM19xma","colab_type":"text"},"source":["# Data Pre-processing"]},{"cell_type":"code","metadata":{"id":"vpTWzGlIXn1D","colab_type":"code","colab":{}},"source":["from nltk.tokenize import word_tokenize\n","from string import punctuation\n","from nltk.corpus import stopwords\n","import re\n","stop_words = set(stopwords.words('english'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xmd31TNL9p8d","colab_type":"code","colab":{}},"source":["def clean_text(reviews_list :list) -> list:\n","  \"\"\"\n","  A function to pre-process text.\n","\n","  This function removes the punctuation marks, numbers and stopwords from the text. It converts the text\n","  to lower case. It also removes reviews with less than 10 words.\n","  Args:\n","    reviews_list: A list of reviews\n","  Returns: \n","    A list of lists where each list corresponds to the words in the corresponding review.\n","\n","  \"\"\"\n","  cleaned_reviews = []\n","  for line in reviews_list:\n","    \n","    line = re.sub(\"\\W\", \" \", line)\n","    #tokenize the sentences into words\n","    tokens = word_tokenize(line)\n","    \n","    words  = [word.lower() for word in tokens if word.isalpha()]\n","    \n","    words = [word for word in words if word not in stop_words]\n","    cleaned_reviews.append(words)\n","\n","\n","  return cleaned_reviews\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6017PNpg9siQ","colab_type":"code","colab":{}},"source":["#test case\n","sample = \"The food was great!! But no AC..delicious....i\"\n","sample_cleaned = clean_text([sample])\n","print(sample_tokenized)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iqpjMRfD94hV","colab_type":"code","colab":{}},"source":["#cleaning the text\n","cleaned_review = clean_text(reviews_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tLIJsK9c-50y","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(cleaned_review, labels, test_size = 0.1, random_state = 100, shuffle=True)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 100, shuffle=True)\n","print(\"Size of training set: \", len(X_train))\n","print(\"Size of validation set: \", len(X_val))\n","print(\"Size of test set: \", len(X_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J9LAvWKOVXAt","colab_type":"code","colab":{}},"source":["#converting to numpy arrays\n","y_train = np.array(y_train)\n","y_val = np.array(y_val)\n","y_test = np.array(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1rja9bQQVR1_","colab_type":"code","colab":{}},"source":["#details about the data\n","y_train_zeroes = np.where(y_train==0)\n","print(\"Number of fake reviews in y_train = \", len(y_train_zeroes[0]))\n","y_val_zeroes = np.where(y_val==0)\n","print(\"Number of fake reviews in y_val = \", len(y_val_zeroes[0]))\n","y_test_zeroes = np.where(y_test==0)\n","print(\"Number of fake reviews in y_test = \", len(y_test_zeroes[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3qYnEcL7BBb1","colab_type":"code","colab":{}},"source":["import collections\n","#finding the average number of words in a review in the training set\n","total_num = 0\n","lengths_dict = collections.defaultdict(int)\n","\n","for review in X_train:\n","  total_num+=len(review)\n","  lengths_dict[len(review)]+=1\n","\n","avg_word_nos = total_num//len(X_train)\n","print(\"Average number of words in a review: \",avg_word_nos)\n","\n","#checking if the average number of words is in the range of the INPUT_LEN\n","if (avg_word_nos > (INPUT_LEN+20)) or (avg_word_nos < (INPUT_LEN-20)):\n","  print(\"Please update your INPUT_LEN variable.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kq46ZiByYYxH","colab_type":"text"},"source":["If training a new model from scratch, create a new tokenizer. <br>\n","If reusing the pre-trained model, then please load the tokenizer from the file"]},{"cell_type":"code","metadata":{"id":"FMO1ta-l-HeB","colab_type":"code","colab":{}},"source":["#defining the tokenizer\n","tokenizer  = tf.keras.preprocessing.text.Tokenizer(num_words = VOCAB_SIZE,lower = True, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kWXW9MLX_KTs","colab_type":"code","colab":{}},"source":["#tokenization and padding\n","X_train_seq = tokenizer.texts_to_sequences(X_train)\n","X_train_seq = np.array(pad_sequences(X_train_seq, INPUT_LEN, padding=\"pre\",truncating=\"post\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B3ExST_gA9HZ","colab_type":"code","colab":{}},"source":["X_val_seq = tokenizer.texts_to_sequences(X_val)\n","X_val_seq = np.array(pad_sequences(X_val_seq, INPUT_LEN, padding=\"pre\",truncating=\"post\"))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cawz0869DGZE","colab_type":"code","colab":{}},"source":["X_test_seq = tokenizer.texts_to_sequences(X_test)\n","X_test_seq = np.array(pad_sequences(X_test_seq, INPUT_LEN, padding=\"pre\",truncating=\"post\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6794_JyUDjGb","colab_type":"text"},"source":["# Building the classifier"]},{"cell_type":"code","metadata":{"id":"5oJP7LKs3JRS","colab_type":"code","colab":{}},"source":["# load the whole embedding into memory\n","embeddings_index = dict()\n","#path to the GloVE 300-dimensional embedding file\n","#download the embeddings from https://nlp.stanford.edu/projects/glove/\n","\n","f = open('glove.6B.300d.txt')\n","\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","\n","f.close()\n","print('Loaded %s word vectors.' % len(embeddings_index))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Lx1Hyiwlbeq","colab_type":"code","colab":{}},"source":["#creating the embedding matrix for the whole vocabulary\n","num_words = len(tokenizer.word_index)+1\n","print(\"Total number words in the vocabulary: \", num_words)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-xRHE6OY3K7R","colab_type":"code","colab":{}},"source":["# create a weight matrix for words in training set\n","embedding_matrix = np.zeros((num_words, 300))\n","\n","for word, i in tokenizer.word_index.items():\n","  \n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None and i<num_words:\n","        embedding_matrix[i] = embedding_vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tD6BGxM-Dkc5","colab_type":"code","colab":{}},"source":["tf.keras.backend.clear_session()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T5kd2cSbDmV_","colab_type":"code","colab":{}},"source":["#hyperparameters\n","num_of_filters = 64\n","kernel_size = 4\n","\n","classifier_model=tf.keras.models.Sequential()\n","#embedding layer\n","classifier_model.add(layers.Embedding(num_words,300,weights=[embedding_matrix], input_length=INPUT_LEN,trainable=False)) \n","\n","#CNN layer\n","classifier_model.add(layers.Conv1D(filters=num_of_filters, kernel_size=kernel_size,activation='relu'))\n","classifier_model.add(layers.MaxPool1D(pool_size=2))\n","classifier_model.add(layers.BatchNormalization())\n","\n","#LSTM\n","classifier_model.add(layers.Bidirectional(layers.LSTM(256, return_sequences=True)))\n","classifier_model.add(layers.Dropout(0.5))\n","\n","classifier_model.add(layers.Bidirectional(layers.LSTM(128, return_sequences=False)))\n","classifier_model.add(layers.Dropout(0.25))\n","\n","#Dense layer\n","classifier_model.add(layers.Dense(128, activation='relu'))\n","classifier_model.add(layers.Dropout(0.25))\n","#classifier_model.add(layers.Dense(64, activation='relu'))\n","classifier_model.add(layers.Dense(32, activation='relu'))\n","classifier_model.add(layers.Dense(2, activation='softmax'))\n","\n","classifier_model.summary()\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b50xo7I9G3C1","colab_type":"code","colab":{}},"source":["#loading the model weights\n","classifier_model.load_weights(\"model_weights/classifier.keras\")\n","classifier_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0015),\n","             loss='categorical_crossentropy',\n","            metrics=['accuracy'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RHBYTGFQG7nC","colab_type":"code","colab":{}},"source":["# Load the extension and start TensorBoard\n","\n","%load_ext tensorboard\n","%tensorboard --logdir logs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DrCT7VdlLTv7","colab_type":"code","colab":{}},"source":["#converting to one hot encoding\n","y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes=2)\n","y_val_one_hot = tf.keras.utils.to_categorical(y_val, num_classes=2)\n","y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aBqdA52vG9DN","colab_type":"code","colab":{}},"source":["from keras.callbacks import TensorBoard\n","from time import time\n","tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X91rCp_uG-y8","colab_type":"code","colab":{}},"source":["history = classifier_model.fit(X_train_seq, y_train_one_hot,\n","                    epochs=5,\n","                    verbose=1,\n","                    batch_size = 256,\n","                    validation_data=(X_val_seq, y_val_one_hot),\n","                    callbacks=[tensorboard]\n","              )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UWjjwDoJPQaR","colab_type":"code","colab":{}},"source":["#saving the model weights\n","classifier_model.save_weights(\"model_weights/classifier_2.keras\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BcLiY15pJFp-","colab_type":"text"},"source":["# Model Evaluation"]},{"cell_type":"code","metadata":{"id":"0_C7x2YCHENL","colab_type":"code","colab":{}},"source":["#getting the prediction classes for the training set\n","train_predictions = classifier_model.predict_classes(X_train_seq)\n","\n","#confusion matrix for the training set\n","conf_mat_train = confusion_matrix(y_train, train_predictions)\n","\n","print(\"Confusion Matrix: \\n\",conf_mat_train )\n","\n","#printing the accuracy on the training set\n","loss,accuracy = classifier_model.evaluate(X_train_seq, y_train_one_hot)\n","print(\"Accuracy on the training set: \", accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZfIVS3lhLRSC","colab_type":"code","colab":{}},"source":["#getting the prediction classes for the validation set\n","val_predictions = classifier_model.predict_classes(X_val_seq)\n","\n","#confusion matrix for the training set\n","conf_mat_val = confusion_matrix(y_val, val_predictions)\n","\n","print(\"Confusion Matrix: \\n\",conf_mat_val )\n","\n","#printing the accuracy on the training set\n","loss,accuracy = classifier_model.evaluate(X_val_seq, y_val_one_hot)\n","print(\"Accuracy on the validation set: \", accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gYyZydZuJeDf","colab_type":"code","colab":{}},"source":["#getting the prediction classes for the test set\n","test_predictions = classifier_model.predict_classes(X_test_seq)\n","\n","#confusion matrix for the training set\n","conf_mat_test = confusion_matrix(y_test, test_predictions)\n","\n","print(\"Confusion Matrix: \\n\",conf_mat_test )\n","\n","#printing the accuracy on the training set\n","loss,accuracy = classifier_model.evaluate(X_test_seq, y_test_one_hot)\n","print(\"Accuracy on the testing set: \", accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"66BRCrznLtDJ","colab_type":"text"},"source":["### Plotting precision-recall curve"]},{"cell_type":"code","metadata":{"id":"H-2nKzdOqbMh","colab_type":"code","colab":{}},"source":["#getting the actual prediction probabilities on training set and extracting the probability for the 0 class\n","t_preds = classifier_model.predict(X_train_seq)\n","t_preds_zeros = t_preds[:, 0]\n","#t_preds_zeros.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OTyzDOq0dFNm","colab_type":"code","colab":{}},"source":["#calculating the precision and recall for the training set\n","t_precision, t_recall, thresholds = precision_recall_curve(y_train, t_preds_zeros, pos_label=0)\n","\n","#finding the precision value at a recall of 90% and the threshold\n","train_ind= 0\n","for i in range(len(t_precision)):\n","  if t_precision[i]>=0.9:\n","    train_ind = i\n","    break\n","print(\"Precision at recall 90%: \", t_precision[train_ind])\n","print(\"Threshold: \", thresholds[train_ind])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f5kKt7pJoBbu","colab_type":"code","colab":{}},"source":["#getting the actual prediction probabilities on validation set and extracting the probability for the 0 class\n","v_preds = classifier_model.predict(X_val_seq)\n","v_preds_zeros = v_preds[:, 0]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFGc7IWFKCol","colab_type":"code","colab":{}},"source":["#calculating the precision and recall for the validation set\n","v_precision, v_recall, v_thresholds = precision_recall_curve(y_val, v_preds_zeros, pos_label=0)\n","\n","#finding the precision value at a recall of 90% and the threshold\n","val_ind= 0\n","for i in range(len(v_precision)):\n","  if v_precision[i]>=0.9:\n","    val_ind = i\n","    break\n","print(\"Precision at recall 90%: \", v_precision[val_ind])\n","print(\"Threshold: \", v_thresholds[val_ind])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HpTmLf2ZJ5nK","colab_type":"code","colab":{}},"source":["#getting the actual prediction probabilities on test set and extracting the probability for the 0 class\n","test_preds = classifier_model.predict(X_test_seq)\n","test_preds_zeros = test_preds[:, 0]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YbTL4lq2KhHB","colab_type":"code","colab":{}},"source":["#calculating the precision and recall for the validation set\n","test_precision, test_recall, test_thresholds = precision_recall_curve(y_test, test_preds_zeros, pos_label=0)\n","\n","#finding the precision value at a recall of 90% and the threshold\n","test_ind= 0\n","for i in range(len(test_precision)):\n","  if test_precision[i]>=0.9:\n","    test_ind = i\n","    break\n","print(\"Precision at recall 90%: \", test_precision[test_ind])\n","print(\"Threshold: \", test_thresholds[test_ind])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n5YlkhDxRcJq","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}