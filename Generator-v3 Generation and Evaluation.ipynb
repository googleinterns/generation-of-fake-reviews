{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Generator-v3 Generation and Evaluation.ipynb","provenance":[{"file_id":"1P57hgNERXaZNTS3MtHHq8LkNpuuFgWPs","timestamp":1595179263435}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xweX7VlCTxlS","colab_type":"text"},"source":["This notebook contains the generation of fake reviews using Generator-v3 and evaluating the Generator model using BLEU scores.\n","<br>\n","**Files Used** <br>\n","Reviews from https://www.kaggle.com/yelp-dataset/yelp-dataset?select=yelp_academic_dataset_review.json <br>\n","Note:<br>\n","Use the same tokenizer that was used for the Generator-v3"]},{"cell_type":"code","metadata":{"id":"3qd3ds2Ly1Df","colab_type":"code","colab":{}},"source":["import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth, drive\n","from oauth2client.client import GoogleCredentials\n","\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3xxCfsL0_dk_","colab_type":"code","colab":{}},"source":["#importing the libraries\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import random\n","from random import choice\n","import time\n","from collections import Counter\n","from nltk.util import ngrams \n","import copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"99PqA2nLzc5D","colab_type":"code","colab":{}},"source":["import nltk\n","nltk.download(\"punkt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fzvSSGAOq72z","colab_type":"code","colab":{}},"source":["from IPython.display import HTML, display\n","\n","def set_css():\n","  \"\"\"A function for wrapping text displayed in the output.\"\"\"\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","  \n","get_ipython().events.register('pre_run_cell', set_css)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yLeNvyHD-d6d","colab_type":"code","colab":{}},"source":["#defining the constants\n","VOCAB_SIZE = 10000\n","INPUT_LEN = 9\n","EMBEDDING_DIM = 300"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mUbdPGk-p4OQ","colab_type":"text"},"source":["# Loading the dataset"]},{"cell_type":"code","metadata":{"id":"4WYKRlSqzVsf","colab_type":"code","colab":{}},"source":["#importing the dataset\n","df = pd.read_csv(\"reviews.csv\")\n","positive_review_ratings = [5]\n","positive_reviews_df = df[df.stars.isin(positive_review_ratings)].reset_index(drop=True)\n","reviews_list = positive_reviews_df[\"text\"].values.tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u3P_6W98UMH6","colab_type":"code","colab":{}},"source":["import re\n","from string import punctuation\n","from nltk.tokenize import sent_tokenize\n","\n","punc = set(punctuation)\n","\n","full_stop_pattern = \"\\.(?=\\S)\"\n","full_stop_pattern = re.compile(full_stop_pattern)\n","\n","qmark_pattern = \"(?=\\S)\\?\"\n","qmark_pattern = re.compile(qmark_pattern)\n","\n","exclmark_pattern = re.compile(\"(?=\\S)\\!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y6H_r21u0wce","colab_type":"code","colab":{}},"source":["def modify_text(text :str) -> str:\n","  \"\"\"\n","    A function to pre-preprocess text.\n","    \n","    It removes numbers, repeated punctuations and adds a space before and after .,!\n","    Args:\n","      text: review to be modified\n","    Returns:\n","      A string with the repeated punctuations removed and a space after .,!\n","\n","  \"\"\"\n","  #removing numbers\n","  text = re.sub(\"\\d+\", \"\", text)\n","  \n","  #removing repeated punctuation marks\n","  new_text = \"\"\n","  for i in range(len(text)):\n","    \n","    #if its not a punctuation mark then add it to the new_text\n","    if text[i] not in punc:\n","      new_text+=text[i]\n","\n","    #if text[i] is a punctuation mark, then check whether the previous character is not a punctuation mark or a space\n","    elif text[i] in punc and ((text[i-1] not in punc) and (text[i-1]!= \" \")):\n","      new_text+=text[i]\n","  \n","  text = new_text\n","  #removing additional spaces\n","  text = re.sub(' +', ' ', text) \n","\n","  #changing it's to its\n","  text = re.sub(\"it\\'s\", \"its\", text)\n","  text = re.sub(\"It\\'s\", \"its\", text)\n","  \n","  #removing the new line character\n","  text = re.sub(\"(\\n)+\", \" \", text)\n","  \n","  #replacing common patterns\n","  text = re.sub(\"\\'ve\", \" have\", text)\n","  text = re.sub(\"don't\", \" do not\", text)\n","  text = re.sub(\"\\'t\", \" not\", text)\n","  text = re.sub(\"\\'m\", \" am\", text)  \n","\n","  #removing the single quotes\n","  text = re.sub(\"\\'\", \"\", text)\n","  #the tokens like !,?,. are considered as separate tokens. \n","  #Hence a space is added before/after them to make the get recognized as separate tokens.\n","\n","  # adding space after the full stop\n","  text = re.sub(full_stop_pattern, \". \", text)\n","\n","  #adding a space before ?\n","  text = re.sub(qmark_pattern, \" ?\", text)\n","\n","  #adding a space before !\n","  text = re.sub(exclmark_pattern, \" !\", text)\n","  \n","  return text\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SLeXq0sk3FgJ","colab_type":"code","colab":{}},"source":["#the punctuation marks like !, ,, . are not to be removed from the text. So they are removed from the set of punctuations\n","import string\n","punc_s = string.punctuation\n","punc_s=punc_s.replace(\"!\",'')\n","punc_s=punc_s.replace(\".\",'')\n","punc_s"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EjZagWr9UT5N","colab_type":"code","colab":{}},"source":["import string\n","from nltk.tokenize import word_tokenize\n","from string import punctuation\n","\n","#to remove punctuations\n","table = str.maketrans('', '', punc_s)\n","punctuations_set = set(punc_s)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1VoRSAuC1Trt","colab_type":"code","colab":{}},"source":["def tokenize_text(reviews_list :list) -> list:\n","  \"\"\"\n","  A function to tokenize the review into words and removes the reviews that have less than 10 words\n","\n","  Args:\n","    reviews_list: A list of reviews\n","  Returns: \n","    A list of lists where each list corresponds to the words in the corresponding review.\n","\n","  \"\"\" \n","  cleaned_reviews = []\n","  for line in reviews_list:\n","    #tokenize the sentences into words\n","    tokens = word_tokenize(line)\n","\n","    #removing the unnecessary punctuation marks\n","    stripped = [w.translate(table) for w in tokens]\n","    \n","    #choosing a word only if it is not a digit or an unnecessary punctuation\n","    words = [word for word in stripped if (word not in punctuations_set)]\n","    \n","    #taking only the reviews whose length is greater than 10.\n","    if len(words)>10:\n","      tokens = [w.lower() for w in words if len(w)>0]\n","      cleaned_reviews.append(tokens)\n","\n","  return cleaned_reviews\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lpp2HqE5-aqP","colab_type":"text"},"source":["## Loading the GLoVE embeddings"]},{"cell_type":"code","metadata":{"id":"5cF2a_h4_CKm","colab_type":"code","colab":{}},"source":["#tokenizer for the GloVE model. Use the same tokenizer generated for generator.\n","with open(\"tokenizer_generator_3.pkl\", \"rb\") as f:\n","  tokenizer = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5oJP7LKs3JRS","colab_type":"code","colab":{}},"source":["# load the whole embedding into memory\n","embeddings_index = dict()\n","\n","#use the path to the GloVE 300 dimensional vectors file\n","#download the embeddings file from https://nlp.stanford.edu/projects/glove/\n","f = open('glove.6B.300d.txt')\n","\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","\n","f.close()\n","print('Loaded %s word vectors.' % len(embeddings_index))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-xRHE6OY3K7R","colab_type":"code","colab":{}},"source":["# create a weight matrix for words in training docs\n","\n","embedding_matrix = np.zeros((VOCAB_SIZE, 300))\n","\n","for word, i in tokenizer.word_index.items():\n","  \n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None and i<VOCAB_SIZE:\n","        embedding_matrix[i] = embedding_vector"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DdrHtPfQ_fjW","colab_type":"text"},"source":["## DL model"]},{"cell_type":"markdown","metadata":{"id":"5W910jFKxkDF","colab_type":"text"},"source":["### GloVE Model"]},{"cell_type":"code","metadata":{"id":"0LErdxS9-n_e","colab_type":"code","colab":{}},"source":["generator_model=tf.keras.models.Sequential()\n","\n","#embedding layer\n","generator_model.add(layers.Embedding(VOCAB_SIZE,300,weights=[embedding_matrix],input_length=INPUT_LEN,trainable=False)) \n","generator_model.add(layers.BatchNormalization())\n","\n","#LSTM layer\n","generator_model.add(layers.Bidirectional(layers.LSTM(256,return_sequences=True)))\n","generator_model.add(layers.Dropout(0.25))\n","\n","#LSTM layer\n","generator_model.add(layers.Bidirectional(layers.LSTM(128, return_sequences=False)))\n","generator_model.add(layers.Dropout(0.25))\n","\n","#Dense layers \n","generator_model.add(layers.Dense(128)) \n","generator_model.add(layers.Dense(512)) \n","generator_model.add(layers.Dense(VOCAB_SIZE,activation='softmax')) \n","\n","#Print summary of model\n","print(generator_model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"anbblGOm-n9O","colab_type":"code","colab":{}},"source":["#loading the pre-trained weights\n","generator_model.load_weights(\"model_weights/generator_3.keras\")\n","generator_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","             loss='sparse_categorical_crossentropy',\n","            metrics=['accuracy'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bTpIgLdeqfki","colab_type":"text"},"source":["# Sample Review Generation"]},{"cell_type":"code","metadata":{"id":"0xdJ-W-Z_1ex","colab_type":"code","colab":{}},"source":["from keras.preprocessing.sequence import pad_sequences\n","\n","def get_text(generator,seed_text :str, tokenizer) -> list:\n","  \"\"\"\n","  A function to generate the text given the seed text\n","\n","  Args:\n","    generator: Keras model of the generator\n","    seed_text: A string, seed text using which the text should be generated\n","    tokenizer: Keras tokenizer using which the tokens can be converted back to text\n","  Returns:\n","    A list of the words following the seed text\n","  \"\"\"\n","  \n","  new_words = []\n","\n","  word_count = 0\n","  \n","  while(1):\n","    seed_text = seed_text.copy()\n","    encoded = tokenizer.texts_to_sequences([seed_text])\n","    \n","    encoded = pad_sequences(encoded, maxlen=INPUT_LEN, truncating='pre', padding=\"post\")\n","    encoded = np.array(encoded)\n","    \n","    pred = np.argmax(generator.predict(encoded),axis=-1)\n","    \n","    pred_word = \"\"\n","    for word, index in tokenizer.word_index.items():\n","      if index == pred[0]:\n","        pred_word = word\n","        break\n","    \n","    new_words.append(pred_word)\n","    \n","    if (pred_word == \".\") or (pred_word == \"!\") or word_count>100:\n","      break\n","    \n","    word_count+=1\n","    seed_text.append(pred_word)\n","    \n","    seed_text.pop(0)\n","    \n","\n","\n","  return new_words"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cmGj8Hso_2yo","colab_type":"code","colab":{}},"source":["sentence_list = [['amazing', '!', 'we', 'were', 'all', 'so', 'pleasantly', 'surprised', '.'],\n","                  ['its', 'a', 'must', '!', 'if', 'youre', 'a', 'meat', 'lover'],\n","                  ['ice', 'cream', 'in', 'arizona', 'is', 'especially', 'good', '.', 'its'],\n","                 \n","                ]\n","for lst in sentence_list:\n","  print(\"Input Sequence: \", ' '.join(lst))\n","  print(\"Generated Sequence: \", ' '.join(get_text(generator_model, lst,tokenizer)))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wWz2VyXJqvrH","colab_type":"code","colab":{}},"source":["#creating the sample tests list\n","tokens_list = reviews_list[:100]\n","\n","#modifying the text\n","for i in range(100):\n","  tokens_list[i] = modify_text(tokens_list[i])\n","\n","#tokenizing the reviews\n","tokens_list = tokenize_text(tokens_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RXWp_caK2cGe","colab_type":"code","colab":{}},"source":["#sample review ouput and comparison with the real reviews\n","for i in range(5):\n","  print(\"Seed Text: \", ' '.join(tokens_list[i][:9]))\n","  print(\"Generated: \", ' '.join(get_text(generator_model, tokens_list[i][:9].copy(), tokenizer)))\n","  print(\"Actual: \", ' '.join(tokens_list[i][9:]))\n","  print()\n","  print()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wjNkVOMsGfOw","colab_type":"text"},"source":["# Model Evaluation\n","The model is evaluated using the BLEU score"]},{"cell_type":"code","metadata":{"id":"fMyUT7mAAbNi","colab_type":"code","colab":{}},"source":["#construction of the reference list for the BLEU score evaluation\n","reference = tokens_list.copy()\n","print(\"Number of reference sentences: \",len(tokens_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V56galjglq69","colab_type":"code","colab":{}},"source":["#construction of the hypothesis list for the BLEU score evaluation\n","hyp = []\n","for i in range(len(tokens_list)):\n","  hyp.append(tokens_list[i][:9]+get_text(generator_model, tokens_list[i][:9], tokenizer))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N9OhuTqesWaZ","colab_type":"code","colab":{}},"source":["def calculate_bleu_score(reference_list :list, hypothesis_list :list, n :int) -> float:\n","  \"\"\"\n","  A function to calculate the bleu score of a list of sentences. The clipped count has been used here.\n","\n","  Args:\n","    reference_list: list of list of words from reference sentences\n","    hypothesis_list: list of list of words from hypothesis sentences\n","    n: ngram number\n","  Returns:\n","    A float value which is the average bleu score for the entire list.\n","  \"\"\"\n","  avg = 0\n","  for i in range(len(reference_list)):\n","\n","    #picking out the ngrams and their frequencies from the given inputs\n","    ref_list_ngram = dict(Counter(ngrams(reference_list[i], n)))\n","    hyp_list_ngram = dict(Counter(ngrams(hypothesis_list[i], n)))\n","\n","    #counting the total number of ngrams in the sentence\n","    denominator = sum(hyp_list_ngram.values())\n","\n","    numerator= 0\n","\n","    for key,val in hyp_list_ngram.items():\n","      if key in ref_list_ngram:\n","        \n","        #for each ngram we need the clipped count. so we take minimum of the ngram count in the sentence or in the reference\n","        numerator+=min(ref_list_ngram[key], val)\n","\n","    if denominator!=0:\n","      avg+=(numerator/denominator)\n","    \n","  return avg/len(reference_list)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RaCtnUldvyF_","colab_type":"code","colab":{}},"source":["#test case\n","hyp1 = [\"cat\", \"on\", \"mat\"]\n","ref1 = [\"there\", \"is\", \"a\", \"cat\", \"on\", \"the\", \"mat\"]\n","\n","print(\"BLEU-2 score: \",calculate_bleu_score([ref1], [hyp1], 2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_sVWghzE_LEm","colab_type":"code","colab":{}},"source":["#adding the start tag and end tag for the reference and hypothesis sentences\n","ref2 = copy.deepcopy(tokens_list)\n","for i in range(len(ref2)):\n","  ref2[i].insert(0, \"<s>\")\n","  ref2[i].append(\"</s>\")\n","\n","hyp2 = copy.deepcopy(hyp)\n","for i in range(len(hyp)):\n","  hyp2[i].insert(0, \"<s>\")\n","  hyp2[i].append(\"</s>\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lL7wLs7Cu2rd","colab_type":"code","colab":{}},"source":["#BLEU-1 score\n","print(\"BLEU-1 Score: \",calculate_bleu_score(ref2, hyp2, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nHQqigt6u-YF","colab_type":"code","colab":{}},"source":["#BLEU-2 score\n","print(\"BLEU-2 Score: \",calculate_bleu_score(ref2, hyp2, 2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x4lsKze6_tTu","colab_type":"code","colab":{}},"source":["#BLEU-3 score\n","print(\"BLEU-3 Score: \",calculate_bleu_score(ref2, hyp2, 3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bZlv4gHyeCKB","colab_type":"code","colab":{}},"source":["#BLEU-4 score\n","print(\"BLEU-4 Score: \",calculate_bleu_score(ref2, hyp2, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zJS2mzZFo848","colab_type":"text"},"source":["# Generation of new text"]},{"cell_type":"code","metadata":{"id":"MHX8TAtw3Ztl","colab_type":"code","colab":{}},"source":["from keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KmuhcxvstZ_L","colab_type":"code","colab":{}},"source":["token_to_word = {v:k for k,v in tokenizer.word_index.items()}\n","#defining the empty string token\n","token_to_word[0] = ''\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VB-OA-mxsxJK","colab_type":"code","colab":{}},"source":["def get_full_review(generator,seed_text, tokenizer):\n","  \"\"\"\n","  A function to generate the entire review given the seed text.\n","\n","  The function keeps generating till the review has 3 sentences or 250 words whichever\n","  comes first. \n","  Args:\n","    generator: Keras model of the generator\n","    seed_text: A string, seed text using which the text should be generated\n","    tokenizer: Keras tokenizer using which the tokens can be converted back to text\n","  Returns:\n","    A list of the words following the seed text\n","  \"\"\"  \n","  new_words = []\n","\n","  word_count = 0\n","  sent_count = 0\n","  \n","  while(1):\n","    \n","    encoded = tokenizer.texts_to_sequences([seed_text].copy())\n","    encoded = pad_sequences(encoded, maxlen=INPUT_LEN, truncating='pre', padding=\"post\")\n","    encoded = np.array(encoded)\n","    \n","    pred_probs = generator.predict(encoded)\n","    \n","    word_ind = np.random.choice(VOCAB_SIZE, p=pred_probs[0])\n","    pred_word = token_to_word[word_ind]\n","    \n","    new_words.append(pred_word)\n","    \n","    if (pred_word == \".\") or (pred_word == \"!\"):\n","      sent_count+=1\n","\n","    if sent_count==3 or word_count>250:\n","      seed_text.append(pred_word)\n","      break\n","    \n","    word_count+=1\n","    seed_text.append(pred_word)\n","    \n","    \n","  return ' '.join(seed_text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XOgiMhI4V_Qb","colab_type":"text"},"source":["The process of generating text from LSTM is a bit slow. It takes around 3 hours to generate 10K reviews"]},{"cell_type":"code","metadata":{"id":"cycNkNvqvqEw","colab_type":"code","colab":{}},"source":["#test case\n","print(get_full_review(generator_model, tokens_list[0][:9].copy(), tokenizer))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwaJ1gCXvqCY","colab_type":"code","colab":{}},"source":["#enter the number of reviews to be generated. When needed to generate large number of reviews, use the entire review corpus.\n","new_reviews = []\n","for i in range(10):\n","  new_reviews.append(get_full_review(generator_model, tokens_list[i][:9].copy(), tokenizer))\n"],"execution_count":null,"outputs":[]}]}