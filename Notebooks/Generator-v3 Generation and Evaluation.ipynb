{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Generator-v3 Generation Evaluation.ipynb","provenance":[{"file_id":"1P57hgNERXaZNTS3MtHHq8LkNpuuFgWPs","timestamp":1595179263435}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xweX7VlCTxlS","colab_type":"text"},"source":["This notebook contains the generation of fake reviews using Generator-v3 and evaluating the Generator model using BLEU scores.\n","<br>\n","**Files Used** <br>\n","Reviews File: data/reviews_85K.csv <br>\n","Tokenizer:tokenizers/tokenizer_generator_3.pkl   <br>\n","Model Weights: model_weights/generator_3.keras"]},{"cell_type":"code","metadata":{"id":"3qd3ds2Ly1Df","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1595569294852,"user_tz":-330,"elapsed":19825,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"f614ce58-a9f9-43eb-d1d9-0f293a331d39"},"source":["import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth, drive\n","from oauth2client.client import GoogleCredentials\n","\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3xxCfsL0_dk_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595569297448,"user_tz":-330,"elapsed":7245,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"d7bebba0-2fa5-46e4-95c7-ee04f459d521"},"source":["#importing the libraries\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import random\n","from random import choice\n","import time\n","from collections import Counter\n","from nltk.util import ngrams \n","import copy"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"99PqA2nLzc5D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1595569298198,"user_tz":-330,"elapsed":7820,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"67c9da8f-2c67-4276-affc-0b8ddbf93469"},"source":["import nltk\n","nltk.download(\"punkt\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"fzvSSGAOq72z","colab_type":"code","colab":{}},"source":["from IPython.display import HTML, display\n","\n","def set_css():\n","  \"\"\"A function for wrapping text displayed in the output.\"\"\"\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","  \n","get_ipython().events.register('pre_run_cell', set_css)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yLeNvyHD-d6d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1595569298199,"user_tz":-330,"elapsed":5223,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"2b866c46-179b-49e3-92bf-d7cf69c9df16"},"source":["#defining the constants\n","VOCAB_SIZE = 10000\n","INPUT_LEN = 9\n","EMBEDDING_DIM = 300"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"mUbdPGk-p4OQ","colab_type":"text"},"source":["# Loading the dataset"]},{"cell_type":"code","metadata":{"id":"4WYKRlSqzVsf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1595569821294,"user_tz":-330,"elapsed":2553,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"ad458fe4-59a2-44c0-b961-ca2bfa4b887d"},"source":["#importing the dataset\n","df = pd.read_csv(\"data/reviews_85K.csv\")\n","positive_review_ratings = [5]\n","positive_reviews_df = df[df.stars.isin(positive_review_ratings)].reset_index(drop=True)\n","reviews_list = positive_reviews_df[\"text\"].values.tolist()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"u3P_6W98UMH6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1595569828559,"user_tz":-330,"elapsed":785,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"b244a6fe-275c-4d29-fdd1-24d8295ae964"},"source":["import re\n","from string import punctuation\n","from nltk.tokenize import sent_tokenize\n","\n","punc = set(punctuation)\n","\n","full_stop_pattern = \"\\.(?=\\S)\"\n","full_stop_pattern = re.compile(full_stop_pattern)\n","\n","qmark_pattern = \"(?=\\S)\\?\"\n","qmark_pattern = re.compile(qmark_pattern)\n","\n","exclmark_pattern = re.compile(\"(?=\\S)\\!\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"y6H_r21u0wce","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1595569828562,"user_tz":-330,"elapsed":669,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"c1b2c16a-311c-4a3f-e306-43756b4e05d1"},"source":["def modify_text(text :str) -> str:\n","  \"\"\"\n","    A function to pre-preprocess text.\n","    \n","    It removes numbers, repeated punctuations and adds a space before and after .,!\n","    Args:\n","      text: review to be modified\n","    Returns:\n","      A string with the repeated punctuations removed and a space after .,!\n","\n","  \"\"\"\n","  #removing numbers\n","  text = re.sub(\"\\d+\", \"\", text)\n","  \n","  #removing repeated punctuation marks\n","  new_text = \"\"\n","  for i in range(len(text)):\n","    \n","    #if its not a punctuation mark then add it to the new_text\n","    if text[i] not in punc:\n","      new_text+=text[i]\n","\n","    #if text[i] is a punctuation mark, then check whether the previous character is not a punctuation mark or a space\n","    elif text[i] in punc and ((text[i-1] not in punc) and (text[i-1]!= \" \")):\n","      new_text+=text[i]\n","  \n","  text = new_text\n","  #removing additional spaces\n","  text = re.sub(' +', ' ', text) \n","\n","  #changing it's to its\n","  text = re.sub(\"it\\'s\", \"its\", text)\n","  text = re.sub(\"It\\'s\", \"its\", text)\n","  \n","  #removing the new line character\n","  text = re.sub(\"(\\n)+\", \" \", text)\n","  \n","  #replacing common patterns\n","  text = re.sub(\"\\'ve\", \" have\", text)\n","  text = re.sub(\"don't\", \" do not\", text)\n","  text = re.sub(\"\\'t\", \" not\", text)\n","  text = re.sub(\"\\'m\", \" am\", text)  \n","\n","  #removing the single quotes\n","  text = re.sub(\"\\'\", \"\", text)\n","  #the tokens like !,?,. are considered as separate tokens. \n","  #Hence a space is added before/after them to make the get recognized as separate tokens.\n","\n","  # adding space after the full stop\n","  text = re.sub(full_stop_pattern, \". \", text)\n","\n","  #adding a space before ?\n","  text = re.sub(qmark_pattern, \" ?\", text)\n","\n","  #adding a space before !\n","  text = re.sub(exclmark_pattern, \" !\", text)\n","  \n","  return text\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"SLeXq0sk3FgJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":37},"executionInfo":{"status":"ok","timestamp":1595569830263,"user_tz":-330,"elapsed":848,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"7b68aa46-337b-4297-c593-f3add0baa03d"},"source":["#the punctuation marks like !, ,, . are not to be removed from the text. So they are removed from the set of punctuations\n","import string\n","punc_s = string.punctuation\n","punc_s=punc_s.replace(\"!\",'')\n","punc_s=punc_s.replace(\".\",'')\n","punc_s"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~'"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"EjZagWr9UT5N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1595569830266,"user_tz":-330,"elapsed":651,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"745d4757-4569-42d6-dfaf-03ae7a40b415"},"source":["import string\n","from nltk.tokenize import word_tokenize\n","from string import punctuation\n","\n","#to remove punctuations\n","table = str.maketrans('', '', punc_s)\n","punctuations_set = set(punc_s)\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"1VoRSAuC1Trt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1595569833540,"user_tz":-330,"elapsed":1175,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"b618c9a9-8fe3-4319-ff9f-e9e1b3aac576"},"source":["def tokenize_text(reviews_list :list) -> list:\n","  \"\"\"\n","  A function to tokenize the review into words and removes the reviews that have less than 10 words\n","\n","  Args:\n","    reviews_list: A list of reviews\n","  Returns: \n","    A list of lists where each list corresponds to the words in the corresponding review.\n","\n","  \"\"\" \n","  cleaned_reviews = []\n","  for line in reviews_list:\n","    #tokenize the sentences into words\n","    tokens = word_tokenize(line)\n","\n","    #removing the unnecessary punctuation marks\n","    stripped = [w.translate(table) for w in tokens]\n","    \n","    #choosing a word only if it is not a digit or an unnecessary punctuation\n","    words = [word for word in stripped if (word not in punctuations_set)]\n","    \n","    #taking only the reviews whose length is greater than 10.\n","    if len(words)>10:\n","      tokens = [w.lower() for w in words if len(w)>0]\n","      cleaned_reviews.append(tokens)\n","\n","  return cleaned_reviews\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Lpp2HqE5-aqP","colab_type":"text"},"source":["## Loading the GLoVE embeddings"]},{"cell_type":"code","metadata":{"id":"5cF2a_h4_CKm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1595569322308,"user_tz":-330,"elapsed":1400,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"29d04a28-987a-43b6-d77c-2d44fc03a3f2"},"source":["#tokenizer for the GloVE model\n","with open(\"tokenizers/tokenizer_generator_3.pkl\", \"rb\") as f:\n","  tokenizer = pickle.load(f)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"5oJP7LKs3JRS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595569389884,"user_tz":-330,"elapsed":42910,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"e0a9b0c6-0c1c-4143-9fbb-22084552747a"},"source":["# load the whole embedding into memory\n","embeddings_index = dict()\n","\n","#use the path to the GloVE 300 dimensional vectors file\n","#download the embeddings file from https://nlp.stanford.edu/projects/glove/\n","f = open('glove.6B.300d.txt')\n","\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","\n","f.close()\n","print('Loaded %s word vectors.' % len(embeddings_index))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Loaded 400000 word vectors.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-xRHE6OY3K7R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1595569389886,"user_tz":-330,"elapsed":37692,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"550f6b63-c670-4e6e-c81f-932dd6aa21df"},"source":["# create a weight matrix for words in training docs\n","\n","embedding_matrix = np.zeros((VOCAB_SIZE, 300))\n","\n","for word, i in tokenizer.word_index.items():\n","  \n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None and i<VOCAB_SIZE:\n","        embedding_matrix[i] = embedding_vector"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"DdrHtPfQ_fjW","colab_type":"text"},"source":["## DL model"]},{"cell_type":"markdown","metadata":{"id":"5W910jFKxkDF","colab_type":"text"},"source":["### GloVE Model"]},{"cell_type":"code","metadata":{"id":"0LErdxS9-n_e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":492},"executionInfo":{"status":"ok","timestamp":1595569392351,"user_tz":-330,"elapsed":35237,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"f1fcb17a-e184-4c50-f699-3dbd27bd77fb"},"source":["generator_model=tf.keras.models.Sequential()\n","\n","#embedding layer\n","generator_model.add(layers.Embedding(VOCAB_SIZE,300,weights=[embedding_matrix],input_length=INPUT_LEN,trainable=False)) \n","generator_model.add(layers.BatchNormalization())\n","\n","#LSTM layer\n","generator_model.add(layers.Bidirectional(layers.LSTM(256,return_sequences=True)))\n","generator_model.add(layers.Dropout(0.25))\n","\n","#LSTM layer\n","generator_model.add(layers.Bidirectional(layers.LSTM(128, return_sequences=False)))\n","generator_model.add(layers.Dropout(0.25))\n","\n","#Dense layers \n","generator_model.add(layers.Dense(128)) \n","generator_model.add(layers.Dense(512)) \n","generator_model.add(layers.Dense(VOCAB_SIZE,activation='softmax')) \n","\n","#Print summary of model\n","print(generator_model.summary())"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 9, 300)            3000000   \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 9, 300)            1200      \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 9, 512)            1140736   \n","_________________________________________________________________\n","dropout (Dropout)            (None, 9, 512)            0         \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 256)               656384    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               32896     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               66048     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10000)             5130000   \n","=================================================================\n","Total params: 10,027,264\n","Trainable params: 7,026,664\n","Non-trainable params: 3,000,600\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"anbblGOm-n9O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1595569395127,"user_tz":-330,"elapsed":2761,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"23aad78a-5c21-4ce3-99f7-2b796a714b58"},"source":["#loading the pre-trained weights\n","generator_model.load_weights(\"model_weights/generator_3.keras\")\n","generator_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","             loss='sparse_categorical_crossentropy',\n","            metrics=['accuracy'])\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"bTpIgLdeqfki","colab_type":"text"},"source":["# Sample Review Generation"]},{"cell_type":"code","metadata":{"id":"0xdJ-W-Z_1ex","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1595569588650,"user_tz":-330,"elapsed":886,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"30e3b9d2-ce52-4a9d-a577-68f5eadb1f45"},"source":["from keras.preprocessing.sequence import pad_sequences\n","\n","def get_text(generator,seed_text :str, tokenizer) -> list:\n","  \"\"\"\n","  A function to generate the text given the seed text\n","\n","  Args:\n","    generator: Keras model of the generator\n","    seed_text: A string, seed text using which the text should be generated\n","    tokenizer: Keras tokenizer using which the tokens can be converted back to text\n","  Returns:\n","    A list of the words following the seed text\n","  \"\"\"\n","  \n","  new_words = []\n","\n","  word_count = 0\n","  \n","  while(1):\n","    seed_text = seed_text.copy()\n","    encoded = tokenizer.texts_to_sequences([seed_text])\n","    \n","    encoded = pad_sequences(encoded, maxlen=INPUT_LEN, truncating='pre', padding=\"post\")\n","    encoded = np.array(encoded)\n","    \n","    pred = np.argmax(generator.predict(encoded),axis=-1)\n","    \n","    pred_word = \"\"\n","    for word, index in tokenizer.word_index.items():\n","      if index == pred[0]:\n","        pred_word = word\n","        break\n","    \n","    new_words.append(pred_word)\n","    \n","    if (pred_word == \".\") or (pred_word == \"!\") or word_count>100:\n","      break\n","    \n","    word_count+=1\n","    seed_text.append(pred_word)\n","    \n","    seed_text.pop(0)\n","    \n","\n","\n","  return new_words"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"cmGj8Hso_2yo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1595569671993,"user_tz":-330,"elapsed":1838,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"73ecb841-eda6-47e0-b694-311a46d1500d"},"source":["sentence_list = [['amazing', '!', 'we', 'were', 'all', 'so', 'pleasantly', 'surprised', '.'],\n","                  ['its', 'a', 'must', '!', 'if', 'youre', 'a', 'meat', 'lover'],\n","                  ['ice', 'cream', 'in', 'arizona', 'is', 'especially', 'good', '.', 'its'],\n","                 \n","                ]\n","for lst in sentence_list:\n","  print(\"Input Sequence: \", ' '.join(lst))\n","  print(\"Generated Sequence: \", ' '.join(get_text(generator_model, lst,tokenizer)))\n","\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Input Sequence:  amazing ! we were all so pleasantly surprised .\n","Generated Sequence:  the food was delicious and the service was great .\n","Input Sequence:  its a must ! if youre a meat lover\n","Generated Sequence:  you will not be disappointed .\n","Input Sequence:  ice cream in arizona is especially good . its\n","Generated Sequence:  a little pricey but worth it .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wWz2VyXJqvrH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1595569846988,"user_tz":-330,"elapsed":1236,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"498b93c6-31ad-4eed-9fa9-f68a62039ef9"},"source":["#creating the sample tests list\n","tokens_list = reviews_list[:100]\n","\n","#modifying the text\n","for i in range(100):\n","  tokens_list[i] = modify_text(tokens_list[i])\n","\n","#tokenizing the reviews\n","tokens_list = tokenize_text(tokens_list)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"RXWp_caK2cGe","colab_type":"code","colab":{}},"source":["#sample review ouput and comparison with the real reviews\n","for i in range(5):\n","  print(\"Seed Text: \", ' '.join(tokens_list[i][:9]))\n","  print(\"Generated: \", ' '.join(get_text(generator_model, tokens_list[i][:9].copy(), tokenizer)))\n","  print(\"Actual: \", ' '.join(tokens_list[i][9:]))\n","  print()\n","  print()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wjNkVOMsGfOw","colab_type":"text"},"source":["# Model Evaluation\n","The model is evaluated using the BLEU score"]},{"cell_type":"code","metadata":{"id":"fMyUT7mAAbNi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595569866861,"user_tz":-330,"elapsed":846,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"5b1a96fb-cf72-47dc-8fc7-219f527d6bb6"},"source":["#construction of the reference list for the BLEU score evaluation\n","reference = tokens_list.copy()\n","print(\"Number of reference sentences: \",len(tokens_list))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Number of reference sentences:  98\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V56galjglq69","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1595569888798,"user_tz":-330,"elapsed":22541,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"b9c8d418-e7d1-4e8f-b0a6-94480a7f5d86"},"source":["#construction of the hypothesis list for the BLEU score evaluation\n","hyp = []\n","for i in range(len(tokens_list)):\n","  hyp.append(tokens_list[i][:9]+get_text(generator_model, tokens_list[i][:9], tokenizer))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"N9OhuTqesWaZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1595569747064,"user_tz":-330,"elapsed":1025,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"4cbe4415-55e8-4e43-8d76-33d37411fd02"},"source":["def calculate_bleu_score(reference_list :list, hypothesis_list :list, n :int) -> float:\n","  \"\"\"\n","  A function to calculate the bleu score of a list of sentences. The clipped count has been used here.\n","\n","  Args:\n","    reference_list: list of list of words from reference sentences\n","    hypothesis_list: list of list of words from hypothesis sentences\n","    n: ngram number\n","  Returns:\n","    A float value which is the average bleu score for the entire list.\n","  \"\"\"\n","  avg = 0\n","  for i in range(len(reference_list)):\n","\n","    #picking out the ngrams and their frequencies from the given inputs\n","    ref_list_ngram = dict(Counter(ngrams(reference_list[i], n)))\n","    hyp_list_ngram = dict(Counter(ngrams(hypothesis_list[i], n)))\n","\n","    #counting the total number of ngrams in the sentence\n","    denominator = sum(hyp_list_ngram.values())\n","\n","    numerator= 0\n","\n","    for key,val in hyp_list_ngram.items():\n","      if key in ref_list_ngram:\n","        \n","        #for each ngram we need the clipped count. so we take minimum of the ngram count in the sentence or in the reference\n","        numerator+=min(ref_list_ngram[key], val)\n","\n","    if denominator!=0:\n","      avg+=(numerator/denominator)\n","    \n","  return avg/len(reference_list)\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"RaCtnUldvyF_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595569761806,"user_tz":-330,"elapsed":814,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"460e700a-eca1-46b9-835b-2e77be08f2a7"},"source":["#test case\n","hyp1 = [\"cat\", \"on\", \"mat\"]\n","ref1 = [\"there\", \"is\", \"a\", \"cat\", \"on\", \"the\", \"mat\"]\n","\n","print(\"BLEU-2 score: \",calculate_bleu_score([ref1], [hyp1], 2))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["BLEU-2 score:  0.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_sVWghzE_LEm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1595569914058,"user_tz":-330,"elapsed":1047,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"a5a5cc8a-dd0f-4069-d55c-96fdbe94e253"},"source":["#adding the start tag and end tag for the reference and hypothesis sentences\n","ref2 = copy.deepcopy(tokens_list)\n","for i in range(len(ref2)):\n","  ref2[i].insert(0, \"<s>\")\n","  ref2[i].append(\"</s>\")\n","\n","hyp2 = copy.deepcopy(hyp)\n","for i in range(len(hyp)):\n","  hyp2[i].insert(0, \"<s>\")\n","  hyp2[i].append(\"</s>\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"lL7wLs7Cu2rd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595569922688,"user_tz":-330,"elapsed":753,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"6d776b40-1517-468d-a327-2b4f64776575"},"source":["#BLEU-1 score\n","print(\"BLEU-1 Score: \",calculate_bleu_score(ref2, hyp2, 1))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["BLEU-1 Score:  0.8512079425018366\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nHQqigt6u-YF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595569926390,"user_tz":-330,"elapsed":1014,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"9122adf5-c7ea-46ec-ce5e-b2cddc32da5c"},"source":["#BLEU-2 score\n","print(\"BLEU-2 Score: \",calculate_bleu_score(ref2, hyp2, 2))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["BLEU-2 Score:  0.6879437496215393\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4lsKze6_tTu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595569935254,"user_tz":-330,"elapsed":893,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"21aeae6c-6ab3-4749-df55-72633caac180"},"source":["#BLEU-3 score\n","print(\"BLEU-3 Score: \",calculate_bleu_score(ref2, hyp2, 3))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["BLEU-3 Score:  0.6199415514137441\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bZlv4gHyeCKB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595569943770,"user_tz":-330,"elapsed":733,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"4d6c86ff-60a2-494a-8af5-893e5bb1d505"},"source":["#BLEU-4 score\n","print(\"BLEU-4 Score: \",calculate_bleu_score(ref2, hyp2, 1))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["BLEU-4 Score:  0.8512079425018366\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zJS2mzZFo848","colab_type":"text"},"source":["# Generation of new text"]},{"cell_type":"code","metadata":{"id":"MHX8TAtw3Ztl","colab_type":"code","colab":{}},"source":["from keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KmuhcxvstZ_L","colab_type":"code","colab":{}},"source":["token_to_word = {v:k for k,v in tokenizer.word_index.items()}\n","#defining the empty string token\n","token_to_word[0] = ''\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VB-OA-mxsxJK","colab_type":"code","colab":{}},"source":["def get_full_review(generator,seed_text, tokenizer):\n","  \"\"\"\n","  A function to generate the entire review given the seed text.\n","\n","  The function keeps generating till the review has 3 sentences or 250 words whichever\n","  comes first. \n","  Args:\n","    generator: Keras model of the generator\n","    seed_text: A string, seed text using which the text should be generated\n","    tokenizer: Keras tokenizer using which the tokens can be converted back to text\n","  Returns:\n","    A list of the words following the seed text\n","  \"\"\"  \n","  new_words = []\n","\n","  word_count = 0\n","  sent_count = 0\n","  \n","  while(1):\n","    \n","    encoded = tokenizer.texts_to_sequences([seed_text].copy())\n","    encoded = pad_sequences(encoded, maxlen=INPUT_LEN, truncating='pre', padding=\"post\")\n","    encoded = np.array(encoded)\n","    \n","    pred_probs = generator.predict(encoded)\n","    \n","    word_ind = np.random.choice(VOCAB_SIZE, p=pred_probs[0])\n","    pred_word = token_to_word[word_ind]\n","    \n","    new_words.append(pred_word)\n","    \n","    if (pred_word == \".\") or (pred_word == \"!\"):\n","      sent_count+=1\n","\n","    if sent_count==3 or word_count>250:\n","      seed_text.append(pred_word)\n","      break\n","    \n","    word_count+=1\n","    seed_text.append(pred_word)\n","    \n","    \n","  return ' '.join(seed_text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XOgiMhI4V_Qb","colab_type":"text"},"source":["The process of generating text from LSTM is a bit slow. It takes around 3 hours to generate 10K reviews"]},{"cell_type":"code","metadata":{"id":"cycNkNvqvqEw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1595178999855,"user_tz":-330,"elapsed":2711,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"549266dc-ca48-4682-f70a-3d0e8df04ad3"},"source":["#test case\n","print(get_full_review(generator_model, tokens_list[0][:9].copy(), tokenizer))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["these empanadas are excellent we are argentinean so we thought we would try everything . their chicken plates plate are to die for and the ambiance is charming as well to the point to arrive a day after pm our waitress was very attentive and helpful . we had the eggplant parm the veal and the roasted corn chips .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PwaJ1gCXvqCY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1594831532637,"user_tz":-330,"elapsed":14978,"user":{"displayName":"Ishwarya Sivakumar","photoUrl":"","userId":"02628689146101986402"}},"outputId":"ed2863e0-5500-47f0-c123-428041cd60a9"},"source":["#enter the number of reviews to be generated. When needed to generate large number of reviews, use the entire review corpus.\n","new_reviews = []\n","for i in range(10):\n","  new_reviews.append(get_full_review(generator_model, tokens_list[i][:9].copy(), tokenizer))\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]}]}